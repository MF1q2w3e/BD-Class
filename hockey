@@ -0,0 +1,95 @@
##########################################
### WEEK 3 HOMEWORK NHL HOCKEY ANALYSIS###
##########################################
echo # Big-Data >> README.md
git init
git add README.md
git commit -m "first commit"
git remote add origin https://github.com/moiz15/Big-Data.git
git push -u origin master
#####################################################################
### PACKAGES NEEDED: gamlr, matrix
### Class code needed naref.R
### Note that the hockey data is embedded within the gamlr package


### SET UP: BUILD KEY DATA ELEMENTS FOR USE IN ALL QUESTIONS
library(gamlr) # loads Matrix as well
data(hockey) # load the data
# If additional packages or data are neecded for your code, please add them here

# Optional: check out the readme for the hockey dataset
help(hockey) # describes the hockey data and shows an example regression


## Use Matrix to Prep the data for use by gamlr, creating the data structure we discussed in class
# Combine the covariates all together
x <- cBind(config,team,player) # cBind binds together two sparse matrices
# build 'y': home vs away, binary response
y <- goal$homegoal

## Run an initial gamlr regression on the NHL data
# builds the 
nhlreg <- gamlr(x, y, 
                free=1:(ncol(config)+ncol(team)), ## free denotes unpenalized columns
                family="binomial", standardize=FALSE)## Per the prof, its really rare NOT to standardize the data

## coefficients (grab only the players)
# AICc selection 
Baicc <- coef(nhlreg)[colnames(player),]





### QUESTION 1 -- NAREEN
# [1] Interpret AICc selected model from my nhlreg lasso.
# Just tell some stories about what the model tells you.



### QUESTION 2 -- MATT
# [2] The gamlr run for nhlreg uses standardize=FALSE.
# Why did I do this? What happens if you do standardize?



### QUESTION 3 -- KATERINA
# [3] Compare model selection methods for the nhlreg lasso.
# Consider both IC and CV (you'll want to create cv.nhlreg).

# Plot the overall regression, just to orient ourselves
plot(nhlreg)

# Run a 10-fold cross validation
cv.nhlreg <- cv.gamlr(x,y, nfold=10, select="min", lambda.min.ratio=.0005, 
                      free=1:(ncol(config)+ncol(team)), ## free denotes unpenalized columns
                      family="binomial", standardize=FALSE)

# Calculate the AICc, AIC and BIC as well
nhlAICc <- AICc(nhlreg, k=2)
nhlAIC <- AIC(nhlreg, k=2)
nhlBIC <- BIC(nhlreg) 

# Return the minimums (in log(lambda) units) found by each method
log(nhlreg$lambda[which.min(nhlAICc)])
log(nhlreg$lambda[which.min(nhlAIC)])
log(nhlreg$lambda[which.min(nhlBIC)])
log(cv.nhlreg$lambda.min)
log(cv.nhlreg$lambda.1se)


# Plot each selection method independently
plot(cv.nhlreg)
plot(AICc(nhlreg))
plot(AIC(nhlreg))
plot(BIC(nhlreg)) 

## Plot the CV curve, with reference lines for the various IC methods
ll <- log(nhlreg$lambda) ## the sequence of lambdas
par(mfrow=c(1,2))
plot(cv.nhlreg)
plot(ll, AIC(nhlreg)/n, 
     xlab="log lambda", ylab="IC/n", pch=21, bg="orange")
abline(v=ll[which.min(AIC(nhlreg))], col="orange", lty=3)
abline(v=ll[which.min(BIC(nhlreg))], col="green", lty=3)
abline(v=ll[which.min(AICc(nhlreg))], col="black", lty=3)
points(ll, BIC(nhlreg)/n, pch=21, bg="green")
points(ll, AICc(nhlreg)/n, pch=21, bg="black")
legend("topleft", bty="n",
       fill=c("black","orange","green"),legend=c("AICc","AIC","BIC"))

  
  ## All metrics plotted together in a path plot.
  plot(nhlreg, col="grey")
  abline(v=ll[which.min(AICc(nhlreg))], col="black", lty=2)
  abline(v=ll[which.min(AIC(nhlreg))], col="orange", lty=2)
  abline(v=ll[which.min(BIC(nhlreg))], col="green", lty=2)
  abline(v=log(cv.nhlreg$lambda.min), col="blue", lty=2)
  abline(v=log(cv.nhlreg$lambda.1se), col="purple", lty=2)
  legend("topright", bty="n", lwd=1, 
         col=c("black","orange","green","blue","purple"),
         legend=c("AICc","AIC","BIC","CV.min","CV.1se"))







### QUESTION 4 -- MOIZ
# [4] We've controlled our estimates for confounding information
# from team effects and special play configuration. How do things
# change if we ignored this info (i.e., fit a player-only model)?
# Which scheme is better (interpretability, CV, and IC)?




### QUESTION 5 -- MATT
# [+] Can you translate player Bk effects into something
# comparable to classic Plus-Minus? How do things compare?

# Definition of classic P-M:
# even-strength goal or shorthanded goal    --> +1
# allowing the goal                         --> -1
# Powerplay                                 --> 0
# Empty net                                 --> 0

# Original attempt: plus_minus <- ifelse(player ==1  & goal$homegoal == 1, 1, ifelse(player == -1 & goal$homegoal ==0, 1, -1))  

# Organize the data by season, let's look at the last 5 seasons of data:
s_1314 <- goal$season=="20132014"
s_1213 <- goal$season=="20122013"
s_1112 <- goal$season=="20112012"
s_1011 <- goal$season=="20102011"
s_0910 <- goal$season=="20092010"

## Get each season's traditional Plus-Minus:
pm_1314 <- colSums(player[s_1314,names(Baicc)])
pm_1213 <- colSums(player[s_1213,names(Baicc)])
pm_1112 <- colSums(player[s_1112,names(Baicc)])
pm_1011 <- colSums(player[s_1011,names(Baicc)])
pm_0910 <- colSums(player[s_0910,names(Baicc)])

## Then grab each season's total number of goals
g_1314 <- colSums(abs(player[s_1314,names(Baicc)]))
g_1213 <- colSums(abs(player[s_1213,names(Baicc)]))
g_1112 <- colSums(abs(player[s_1112,names(Baicc)]))
g_1011 <- colSums(abs(player[s_1011,names(Baicc)]))
g_0910 <- colSums(abs(player[s_0910,names(Baicc)]))

# Next you need to find the probability of a goal for or against an individual player's team, given ALL the data.
p_fa <- 1/(1+exp(-Baicc))

# Take that probability, and find an expected Plus-Minus for each of those seasons in question: 
e_pm_1314 <- g_1314*(2*p_fa-1)
e_pm_1213 <- g_1213*(2*p_fa-1)
e_pm_1112 <- g_1112*(2*p_fa-1)
e_pm_1011 <- g_1011*(2*p_fa-1)
e_pm_0910 <- g_0910*(2*p_fa-1)

# Lastly, organize all the data, and print out each year's Expected Plus-Minus (e_pm_season) and actual Plus-Minus (pm_season) to compare.
comp_1314 <- data.frame(beta=round(Baicc,3),e_pm=round(e_pm_1314,3),pm=round(pm_1314,3))
comp_1213 <- data.frame(beta=round(Baicc,3),e_pm=round(e_pm_1213,3),pm=round(pm_1213,3))
comp_1112 <- data.frame(beta=round(Baicc,3),e_pm=round(e_pm_1112,3),pm=round(pm_1112,3))
comp_1011 <- data.frame(beta=round(Baicc,3),e_pm=round(e_pm_1011,3),pm=round(pm_1011,3))
comp_0910 <- data.frame(beta=round(Baicc,3),e_pm=round(e_pm_0910,3),pm=round(pm_0910,3))

# Order each by Expected Plus-Minus:
comp_1314 <- comp_1314[order(-comp_1314$e_pm),]
comp_1213 <- comp_1213[order(-comp_1213$e_pm),]
comp_1112 <- comp_1112[order(-comp_1112$e_pm),]
comp_1011 <- comp_1011[order(-comp_1011$e_pm),]
comp_0910 <- comp_0910[order(-comp_0910$e_pm),]

# Print out the Top 10 for each season:
print("Expected vs. Actual Plus-Minus for the 2013-2014 NHL Season, Top 10")
print(comp_1314[1:10,])
print("")

print("Expected vs. Actual Plus-Minus for the 2012-2013 NHL Season, Top 10")
print(comp_1213[1:10,])
print("")

print("Expected vs. Actual Plus-Minus for the 2011-2012 NHL Season, Top 10")
print(comp_1112[1:10,])
print("")

print("Expected vs. Actual Plus-Minus for the 2010-2011 NHL Season, Top 10")
print(comp_1011[1:10,])
print("")

print("Expected vs. Actual Plus-Minus for the 2009-2010 NHL Season, Top 10")
print(comp_0910[1:10,])



